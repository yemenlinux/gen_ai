{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eb351ac-0164-4e3e-9bba-f3a0256f0bdb",
   "metadata": {},
   "source": [
    "# Introduction to Prompt Engineering\n",
    "Prompt engineering is the process of designing and optimizing prompts for natural language processing tasks. It involves selecting the right prompts, tuning their parameters, and evaluating their performance. Prompt engineering is crucial for achieving high accuracy and efficiency in NLP models. In this section, we will explore the basics of prompt engineering using the OpenAI models for exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f4997-1635-46b7-b14e-9f43d28fa9fb",
   "metadata": {},
   "source": [
    "### Exercise 1: Tokenization\n",
    "Explore Tokenization using tiktoken, an open-source fast tokenizer from OpenAI\n",
    "See [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst) for more examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84edb4-9042-4745-aef5-8e0fc8aca5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be41eb-1650-4b58-a514-9f40361780dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "# import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "كوكب المشتري هو الكوكب الخامس من الشمس و \\\n",
    "الأكبر في النظام الشمسي. إنه عملاق غازي مع \\\n",
    "كتلتها جزء من ألف من كتلة الشمس، ولكن كتلتها اثنان ونصف \\\n",
    "أضعاف جميع الكواكب الأخرى في النظام الشمسي مجتمعة. \\\n",
    "كوكب المشتري من ألمع الأجسام التي يمكن رؤيتها بالعين المجردة \\\n",
    "في سماء الليل، وقد عرفته الحضارات القديمة منذ \\\n",
    "قبل التاريخ المسجل . سُميت نسبة إلى الإله الروماني جوبيتر.[19] \\\n",
    "عند النظر إلى كوكب المشتري من الأرض، يمكن أن يكون ساطعًا بما يكفي لانعكاسه.\n",
    "الضوء لإلقاء ظلال مرئية،[20] وهو في المتوسط ثالث ألمع \\\n",
    "كائن طبيعي في سماء الليل بعد القمر والزهرة.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e2017-b067-435e-9f0b-7b2d81c608b7",
   "metadata": {},
   "source": [
    "### Exercise 2: Validate OpenAI API Key Setup\n",
    "\n",
    "Run the code below to verify that your OpenAI endpoint is set up correctly. The code just tries a simple basic prompt and validates the completion. Input `oh say can you see` should complete along the lines of `by the dawn's early light..`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fca989-07d9-4c6b-9cec-e15c5f47c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The OpenAI SDK was updated on Nov 8, 2023 with new guidance for migration\n",
    "# See: https://github.com/openai/openai-python/discussions/742\n",
    "\n",
    "## Updated\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "## Updated\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temp=0, token_size=1024):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature = temp, # this is the degree of randomness of the model's output\n",
    "        max_tokens = token_size\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7fe266-acb6-4c61-bbc4-23c5d142cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---------- Call the helper method\n",
    "\n",
    "### 1. Set primary content or prompt text\n",
    "text = f\"\"\"\n",
    "oh say can you see\n",
    "\"\"\"\n",
    "\n",
    "### 2. Use that in the prompt template below\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0c850-f7e5-478c-9d46-90c84603902e",
   "metadata": {},
   "source": [
    "### Exercise 3: Fabrications\n",
    "Explore what happens when you ask the LLM to return completions for a prompt about a topic that may not exist, or about topics that it may not know about because it was outside it's pre-trained dataset (more recent). See how the response changes if you try a different prompt, or a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f298e9-3bac-41aa-a927-294b758c5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "ألف خطة لدرس عن حرب المريخيين عام 2200.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0256a9f1-7111-48e3-9d43-bf398be89a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "ولد خطة لدرس عن حرب المريخيين عام 2076\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea687d8a-d80f-4a63-8a3a-b52c39eb4594",
   "metadata": {},
   "source": [
    "### Exercise 4: Instruction Based \n",
    "Use the \"text\" variable to set the primary content \n",
    "and the \"prompt\" variable to provide an instruction related to that primary content.\n",
    "\n",
    "Here we ask the model to summarize the text for a second-grade student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea19b74-9869-4f5c-8f19-68a16179200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "كوكب المشتري هو الكوكب الخامس من الشمس و \\\n",
    "الأكبر في النظام الشمسي. إنه عملاق غازي مع \\\n",
    "كتلتها جزء من ألف من كتلة الشمس، ولكن كتلتها اثنان ونصف \\\n",
    "أضعاف جميع الكواكب الأخرى في النظام الشمسي مجتمعة. \\\n",
    "كوكب المشتري من ألمع الأجسام التي يمكن رؤيتها بالعين المجردة \\\n",
    "في سماء الليل، وقد عرفته الحضارات القديمة منذ \\\n",
    "قبل التاريخ المسجل . سُميت نسبة إلى الإله الروماني جوبيتر.[19] \\\n",
    "عند النظر إلى كوكب المشتري من الأرض، يمكن أن يكون ساطعًا بما يكفي لانعكاسه.\n",
    "الضوء لإلقاء ظلال مرئية،[20] وهو في المتوسط ثالث ألمع \\\n",
    "كائن طبيعي في سماء الليل بعد القمر والزهرة.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "تلخيص المحتوى المقدم لك لطالب الصف الثاني.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e9259-2210-426d-915b-7a5624afbe14",
   "metadata": {},
   "source": [
    "### Exercise 5: Complex Prompt \n",
    "Try a request that has system, user and assistant messages \n",
    "System sets assistant context\n",
    "User & Assistant messages provide multi-turn conversation context\n",
    "\n",
    "Note how the assistant personality is set to \"sarcastic\" in the system context. \n",
    "Try using a different personality context. Or try a different series of input/output messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c34d7c-d5f0-4bfe-9751-752f6caa41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        # System message setting the context for assistant behavior or personality.\n",
    "        {\"role\": \"system\", \"content\": \"أنت مساعد ساخر\"},\n",
    "        # from chat history\n",
    "        {\"role\": \"user\", \"content\": \"من انتصر في حرب المريخيين عام 2076؟\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"اليمن انتصرت في حرب المريخيين عام 2076\"},\n",
    "        # new question\n",
    "        {\"role\": \"user\", \"content\": \"أين وقعت الحرب؟\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a0366-0dd6-45e3-af81-67059260c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the system role is not great in Arabic, Try it in English.\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        # System message setting the context for assistant behavior or personality.\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"من انتصر في حرب المريخيين عام 2076؟\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"اليمن انتصرت في حرب المريخيين عام 2076\"},\n",
    "        {\"role\": \"user\", \"content\": \"أين وقعت الحرب؟\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4c982-b6e7-45ec-ba78-5618e7fbc737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
