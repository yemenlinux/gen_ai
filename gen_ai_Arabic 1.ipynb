{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eb351ac-0164-4e3e-9bba-f3a0256f0bdb",
   "metadata": {},
   "source": [
    "# Introduction to Prompt Engineering\n",
    "Prompt engineering is the process of designing and optimizing prompts for natural language processing tasks. It involves selecting the right prompts, tuning their parameters, and evaluating their performance. Prompt engineering is crucial for achieving high accuracy and efficiency in NLP models. In this section, we will explore the basics of prompt engineering using the OpenAI models for exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f4997-1635-46b7-b14e-9f43d28fa9fb",
   "metadata": {},
   "source": [
    "### Exercise 1: Tokenization\n",
    "Explore Tokenization using tiktoken, an open-source fast tokenizer from OpenAI\n",
    "See [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst) for more examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d84edb4-9042-4745-aef5-8e0fc8aca5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198, 41, 20089, 374, 279, 18172, 11841, 505, 279, 8219, 323, 279, 7928, 304, 279, 25450, 744, 13, 1102, 374, 264, 6962, 14880, 449, 264, 3148, 832, 7716, 52949, 339, 430, 315, 279, 8219, 11, 719, 1403, 9976, 7561, 34902, 3115, 430, 315, 682, 279, 1023, 33975, 304, 279, 25450, 744, 11093, 13, 50789, 374, 832, 315, 279, 72021, 6302, 9621, 311, 279, 19557, 8071, 304, 279, 3814, 13180, 11, 323, 706, 1027, 3967, 311, 14154, 86569, 2533, 1603, 12715, 3925, 13, 1102, 374, 7086, 1306, 279, 13041, 10087, 50789, 8032, 777, 60, 3277, 19894, 505, 9420, 11, 50789, 649, 387, 10107, 3403, 369, 1202, 27000, 3177, 311, 6445, 9621, 35612, 17706, 508, 60, 323, 374, 389, 5578, 279, 4948, 1481, 1315, 478, 5933, 1665, 304, 279, 3814, 13180, 1306, 279, 17781, 323, 50076, 627]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[b'\\n',\n",
       " b'J',\n",
       " b'upiter',\n",
       " b' is',\n",
       " b' the',\n",
       " b' fifth',\n",
       " b' planet',\n",
       " b' from',\n",
       " b' the',\n",
       " b' Sun',\n",
       " b' and',\n",
       " b' the',\n",
       " b' largest',\n",
       " b' in',\n",
       " b' the',\n",
       " b' Solar',\n",
       " b' System',\n",
       " b'.',\n",
       " b' It',\n",
       " b' is',\n",
       " b' a',\n",
       " b' gas',\n",
       " b' giant',\n",
       " b' with',\n",
       " b' a',\n",
       " b' mass',\n",
       " b' one',\n",
       " b'-th',\n",
       " b'ousand',\n",
       " b'th',\n",
       " b' that',\n",
       " b' of',\n",
       " b' the',\n",
       " b' Sun',\n",
       " b',',\n",
       " b' but',\n",
       " b' two',\n",
       " b'-and',\n",
       " b'-a',\n",
       " b'-half',\n",
       " b' times',\n",
       " b' that',\n",
       " b' of',\n",
       " b' all',\n",
       " b' the',\n",
       " b' other',\n",
       " b' planets',\n",
       " b' in',\n",
       " b' the',\n",
       " b' Solar',\n",
       " b' System',\n",
       " b' combined',\n",
       " b'.',\n",
       " b' Jupiter',\n",
       " b' is',\n",
       " b' one',\n",
       " b' of',\n",
       " b' the',\n",
       " b' brightest',\n",
       " b' objects',\n",
       " b' visible',\n",
       " b' to',\n",
       " b' the',\n",
       " b' naked',\n",
       " b' eye',\n",
       " b' in',\n",
       " b' the',\n",
       " b' night',\n",
       " b' sky',\n",
       " b',',\n",
       " b' and',\n",
       " b' has',\n",
       " b' been',\n",
       " b' known',\n",
       " b' to',\n",
       " b' ancient',\n",
       " b' civilizations',\n",
       " b' since',\n",
       " b' before',\n",
       " b' recorded',\n",
       " b' history',\n",
       " b'.',\n",
       " b' It',\n",
       " b' is',\n",
       " b' named',\n",
       " b' after',\n",
       " b' the',\n",
       " b' Roman',\n",
       " b' god',\n",
       " b' Jupiter',\n",
       " b'.[',\n",
       " b'19',\n",
       " b']',\n",
       " b' When',\n",
       " b' viewed',\n",
       " b' from',\n",
       " b' Earth',\n",
       " b',',\n",
       " b' Jupiter',\n",
       " b' can',\n",
       " b' be',\n",
       " b' bright',\n",
       " b' enough',\n",
       " b' for',\n",
       " b' its',\n",
       " b' reflected',\n",
       " b' light',\n",
       " b' to',\n",
       " b' cast',\n",
       " b' visible',\n",
       " b' shadows',\n",
       " b',[',\n",
       " b'20',\n",
       " b']',\n",
       " b' and',\n",
       " b' is',\n",
       " b' on',\n",
       " b' average',\n",
       " b' the',\n",
       " b' third',\n",
       " b'-b',\n",
       " b'right',\n",
       " b'est',\n",
       " b' natural',\n",
       " b' object',\n",
       " b' in',\n",
       " b' the',\n",
       " b' night',\n",
       " b' sky',\n",
       " b' after',\n",
       " b' the',\n",
       " b' Moon',\n",
       " b' and',\n",
       " b' Venus',\n",
       " b'.\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65be41eb-1650-4b58-a514-9f40361780dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198, 32173, 12942, 32173, 22071, 54579, 33890, 14628, 11318, 14900, 56991, 12942, 17607, 32173, 12942, 32173, 22071, 17607, 36344, 50488, 20665, 64337, 17607, 33890, 10386, 20665, 38624, 17607, 70782, 32173, 84927, 78373, 17607, 12061, 93481, 50488, 17607, 33890, 10386, 20665, 14900, 13, 86253, 12061, 16552, 45082, 10386, 82070, 28590, 8979, 118, 5821, 40797, 14900, 24252, 24102, 88041, 14628, 8700, 14628, 16552, 5821, 83268, 40797, 148, 94, 64337, 64515, 8700, 21604, 64337, 88041, 14628, 8700, 26957, 17607, 33890, 10386, 20665, 69885, 38624, 8700, 32173, 12061, 88041, 14628, 8700, 14628, 16552, 5821, 13258, 85632, 12061, 40523, 38624, 12061, 42693, 21604, 64515, 58959, 24102, 97075, 83268, 10386, 14900, 24102, 17607, 32173, 12942, 5821, 32173, 22071, 17607, 70782, 36344, 11318, 56157, 78373, 17607, 12061, 93481, 50488, 17607, 33890, 10386, 20665, 14900, 24252, 34190, 14628, 10386, 24102, 26957, 13, 88041, 12942, 32173, 22071, 54579, 33890, 14628, 11318, 14900, 64337, 64515, 8700, 10386, 24102, 17607, 70782, 34190, 20665, 50488, 96057, 14900, 74374, 10386, 32173, 12061, 54810, 148, 97, 14900, 14628, 16552, 5821, 28946, 32482, 24102, 14900, 12061, 54579, 34190, 11318, 13628, 26957, 78373, 60942, 10386, 99819, 17607, 8700, 96298, 69885, 38624, 28590, 13628, 45082, 11318, 21604, 14628, 16552, 17607, 30925, 58959, 36138, 48732, 17607, 28590, 80920, 10386, 26957, 64337, 56434, 78803, 22071, 8700, 96057, 36138, 14900, 36344, 54579, 20665, 34190, 8700, 662, 60942, 65704, 10386, 14900, 14628, 51343, 20665, 22071, 26957, 86253, 84659, 17607, 93062, 8700, 16552, 17607, 86096, 10386, 40523, 14900, 83268, 12942, 22071, 14900, 14628, 11318, 8032, 777, 60, 45082, 12061, 13628, 17607, 12061, 93481, 11318, 86253, 84659, 88041, 12942, 32173, 22071, 54579, 33890, 14628, 11318, 14900, 64337, 17607, 70782, 11318, 58959, 69885, 74374, 10386, 32173, 12061, 64515, 12061, 74374, 32173, 12942, 12061, 60942, 5821, 44735, 24102, 149, 233, 5821, 28946, 10386, 5821, 74374, 32173, 21604, 14900, 57894, 40523, 24102, 32173, 92444, 16552, 627, 32482, 58959, 12942, 148, 94, 57894, 93062, 8700, 28590, 99819, 8979, 116, 8700, 32482, 24252, 11318, 148, 99, 74541, 69885, 58, 508, 60, 38624, 16552, 12942, 78373, 54579, 14628, 12942, 20665, 44735, 8979, 104, 32482, 85632, 64515, 8700, 10386, 24102, 88041, 69350, 99, 12061, 8979, 115, 22071, 14900, 24102, 14900, 78373, 60942, 10386, 99819, 17607, 8700, 96298, 28946, 24102, 13628, 17607, 28590, 10386, 11318, 38624, 32482, 40797, 16552, 11318, 26957, 627]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[b'\\n',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd9\\x88',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd8\\xa8',\n",
       " b' \\xd8\\xa7\\xd9\\x84\\xd9\\x85',\n",
       " b'\\xd8\\xb4',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd8\\xb1',\n",
       " b'\\xd9\\x8a',\n",
       " b' \\xd9\\x87',\n",
       " b'\\xd9\\x88',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd9\\x88',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd8\\xa8',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xae',\n",
       " b'\\xd8\\xa7\\xd9\\x85',\n",
       " b'\\xd8\\xb3',\n",
       " b' \\xd9\\x85\\xd9\\x86',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xb4',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xb3',\n",
       " b' \\xd9\\x88',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xa3',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd8\\xa8\\xd8\\xb1',\n",
       " b' \\xd9\\x81\\xd9\\x8a',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd9\\x86',\n",
       " b'\\xd8\\xb8',\n",
       " b'\\xd8\\xa7\\xd9\\x85',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xb4',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xb3',\n",
       " b'\\xd9\\x8a',\n",
       " b'.',\n",
       " b' \\xd8\\xa5',\n",
       " b'\\xd9\\x86',\n",
       " b'\\xd9\\x87',\n",
       " b' \\xd8\\xb9',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd9\\x84\\xd8\\xa7',\n",
       " b'\\xd9\\x82',\n",
       " b' \\xd8',\n",
       " b'\\xba',\n",
       " b'\\xd8\\xa7',\n",
       " b'\\xd8\\xb2',\n",
       " b'\\xd9\\x8a',\n",
       " b' \\xd9\\x85',\n",
       " b'\\xd8\\xb9',\n",
       " b' \\xd9\\x83',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd9\\x84',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd9\\x87',\n",
       " b'\\xd8\\xa7',\n",
       " b' \\xd8\\xac',\n",
       " b'\\xd8\\xb2',\n",
       " b'\\xd8',\n",
       " b'\\xa1',\n",
       " b' \\xd9\\x85\\xd9\\x86',\n",
       " b' \\xd8\\xa3',\n",
       " b'\\xd9\\x84',\n",
       " b'\\xd9\\x81',\n",
       " b' \\xd9\\x85\\xd9\\x86',\n",
       " b' \\xd9\\x83',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd9\\x84',\n",
       " b'\\xd8\\xa9',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xb4',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xb3',\n",
       " b'\\xd8\\x8c',\n",
       " b' \\xd9\\x88',\n",
       " b'\\xd9\\x84',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd9\\x86',\n",
       " b' \\xd9\\x83',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd9\\x84',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd9\\x87',\n",
       " b'\\xd8\\xa7',\n",
       " b' \\xd8\\xa7',\n",
       " b'\\xd8\\xab',\n",
       " b'\\xd9\\x86',\n",
       " b'\\xd8\\xa7\\xd9\\x86',\n",
       " b' \\xd9\\x88',\n",
       " b'\\xd9\\x86',\n",
       " b'\\xd8\\xb5',\n",
       " b'\\xd9\\x81',\n",
       " b' \\xd8\\xa3',\n",
       " b'\\xd8\\xb6',\n",
       " b'\\xd8\\xb9',\n",
       " b'\\xd8\\xa7\\xd9\\x81',\n",
       " b' \\xd8\\xac',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd9\\x8a',\n",
       " b'\\xd8\\xb9',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd9\\x88',\n",
       " b'\\xd8\\xa7',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd8\\xa8',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xa3',\n",
       " b'\\xd8\\xae',\n",
       " b'\\xd8\\xb1',\n",
       " b'\\xd9\\x89',\n",
       " b' \\xd9\\x81\\xd9\\x8a',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd9\\x86',\n",
       " b'\\xd8\\xb8',\n",
       " b'\\xd8\\xa7\\xd9\\x85',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xb4',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xb3',\n",
       " b'\\xd9\\x8a',\n",
       " b' \\xd9\\x85',\n",
       " b'\\xd8\\xac',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xb9',\n",
       " b'\\xd8\\xa9',\n",
       " b'.',\n",
       " b' \\xd9\\x83',\n",
       " b'\\xd9\\x88',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd8\\xa8',\n",
       " b' \\xd8\\xa7\\xd9\\x84\\xd9\\x85',\n",
       " b'\\xd8\\xb4',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd8\\xb1',\n",
       " b'\\xd9\\x8a',\n",
       " b' \\xd9\\x85\\xd9\\x86',\n",
       " b' \\xd8\\xa3',\n",
       " b'\\xd9\\x84',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xb9',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xa3',\n",
       " b'\\xd8\\xac',\n",
       " b'\\xd8\\xb3',\n",
       " b'\\xd8\\xa7\\xd9\\x85',\n",
       " b' \\xd8\\xa7\\xd9\\x84\\xd8\\xaa',\n",
       " b'\\xd9\\x8a',\n",
       " b' \\xd9\\x8a',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd9\\x86',\n",
       " b' \\xd8\\xb1',\n",
       " b'\\xd8',\n",
       " b'\\xa4',\n",
       " b'\\xd9\\x8a',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd9\\x87',\n",
       " b'\\xd8\\xa7',\n",
       " b' \\xd8\\xa8',\n",
       " b'\\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xb9',\n",
       " b'\\xd9\\x8a',\n",
       " b'\\xd9\\x86',\n",
       " b' \\xd8\\xa7\\xd9\\x84\\xd9\\x85',\n",
       " b'\\xd8\\xac',\n",
       " b'\\xd8\\xb1',\n",
       " b'\\xd8\\xaf',\n",
       " b'\\xd8\\xa9',\n",
       " b' \\xd9\\x81\\xd9\\x8a',\n",
       " b' \\xd8\\xb3',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xa7\\xd8\\xa1',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd9\\x84',\n",
       " b'\\xd9\\x8a\\xd9\\x84',\n",
       " b'\\xd8\\x8c',\n",
       " b' \\xd9\\x88',\n",
       " b'\\xd9\\x82',\n",
       " b'\\xd8\\xaf',\n",
       " b' \\xd8\\xb9',\n",
       " b'\\xd8\\xb1',\n",
       " b'\\xd9\\x81',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd9\\x87',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xad',\n",
       " b'\\xd8\\xb6',\n",
       " b'\\xd8\\xa7\\xd8\\xb1',\n",
       " b'\\xd8\\xa7\\xd8\\xaa',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd9\\x82',\n",
       " b'\\xd8\\xaf\\xd9\\x8a',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xa9',\n",
       " b' \\xd9\\x85\\xd9\\x86',\n",
       " b'\\xd8\\xb0',\n",
       " b' \\xd9\\x82',\n",
       " b'\\xd8\\xa8',\n",
       " b'\\xd9\\x84',\n",
       " b' \\xd8\\xa7\\xd9\\x84\\xd8\\xaa',\n",
       " b'\\xd8\\xa7\\xd8\\xb1',\n",
       " b'\\xd9\\x8a',\n",
       " b'\\xd8\\xae',\n",
       " b' \\xd8\\xa7\\xd9\\x84\\xd9\\x85',\n",
       " b'\\xd8\\xb3',\n",
       " b'\\xd8\\xac',\n",
       " b'\\xd9\\x84',\n",
       " b' .',\n",
       " b' \\xd8\\xb3',\n",
       " b'\\xd9\\x8f',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd9\\x8a',\n",
       " b'\\xd8\\xaa',\n",
       " b' \\xd9\\x86',\n",
       " b'\\xd8\\xb3',\n",
       " b'\\xd8\\xa8',\n",
       " b'\\xd8\\xa9',\n",
       " b' \\xd8\\xa5',\n",
       " b'\\xd9\\x84\\xd9\\x89',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xa5',\n",
       " b'\\xd9\\x84',\n",
       " b'\\xd9\\x87',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xb1\\xd9\\x88',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xa7\\xd9\\x86',\n",
       " b'\\xd9\\x8a',\n",
       " b' \\xd8\\xac',\n",
       " b'\\xd9\\x88',\n",
       " b'\\xd8\\xa8',\n",
       " b'\\xd9\\x8a',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd8\\xb1',\n",
       " b'.[',\n",
       " b'19',\n",
       " b']',\n",
       " b' \\xd8\\xb9',\n",
       " b'\\xd9\\x86',\n",
       " b'\\xd8\\xaf',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd9\\x86',\n",
       " b'\\xd8\\xb8',\n",
       " b'\\xd8\\xb1',\n",
       " b' \\xd8\\xa5',\n",
       " b'\\xd9\\x84\\xd9\\x89',\n",
       " b' \\xd9\\x83',\n",
       " b'\\xd9\\x88',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd8\\xa8',\n",
       " b' \\xd8\\xa7\\xd9\\x84\\xd9\\x85',\n",
       " b'\\xd8\\xb4',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd8\\xb1',\n",
       " b'\\xd9\\x8a',\n",
       " b' \\xd9\\x85\\xd9\\x86',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xa3',\n",
       " b'\\xd8\\xb1',\n",
       " b'\\xd8\\xb6',\n",
       " b'\\xd8\\x8c',\n",
       " b' \\xd9\\x8a',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd9\\x86',\n",
       " b' \\xd8\\xa3',\n",
       " b'\\xd9\\x86',\n",
       " b' \\xd9\\x8a',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd9\\x88',\n",
       " b'\\xd9\\x86',\n",
       " b' \\xd8\\xb3',\n",
       " b'\\xd8\\xa7',\n",
       " b'\\xd8\\xb7',\n",
       " b'\\xd8\\xb9',\n",
       " b'\\xd9',\n",
       " b'\\x8b',\n",
       " b'\\xd8\\xa7',\n",
       " b' \\xd8\\xa8',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xa7',\n",
       " b' \\xd9\\x8a',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd9\\x81',\n",
       " b'\\xd9\\x8a',\n",
       " b' \\xd9\\x84',\n",
       " b'\\xd8\\xa7\\xd9\\x86',\n",
       " b'\\xd8\\xb9',\n",
       " b'\\xd9\\x83',\n",
       " b'\\xd8\\xa7\\xd8\\xb3',\n",
       " b'\\xd9\\x87',\n",
       " b'.\\n',\n",
       " b'\\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xb6',\n",
       " b'\\xd9\\x88',\n",
       " b'\\xd8',\n",
       " b'\\xa1',\n",
       " b' \\xd9\\x84',\n",
       " b'\\xd8\\xa5',\n",
       " b'\\xd9\\x84',\n",
       " b'\\xd9\\x82',\n",
       " b'\\xd8\\xa7\\xd8\\xa1',\n",
       " b' \\xd8',\n",
       " b'\\xb8',\n",
       " b'\\xd9\\x84',\n",
       " b'\\xd8\\xa7\\xd9\\x84',\n",
       " b' \\xd9\\x85',\n",
       " b'\\xd8\\xb1',\n",
       " b'\\xd8',\n",
       " b'\\xa6',\n",
       " b'\\xd9\\x8a\\xd8\\xa9',\n",
       " b'\\xd8\\x8c',\n",
       " b'[',\n",
       " b'20',\n",
       " b']',\n",
       " b' \\xd9\\x88',\n",
       " b'\\xd9\\x87',\n",
       " b'\\xd9\\x88',\n",
       " b' \\xd9\\x81\\xd9\\x8a',\n",
       " b' \\xd8\\xa7\\xd9\\x84\\xd9\\x85',\n",
       " b'\\xd8\\xaa',\n",
       " b'\\xd9\\x88',\n",
       " b'\\xd8\\xb3',\n",
       " b'\\xd8\\xb7',\n",
       " b' \\xd8',\n",
       " b'\\xab',\n",
       " b'\\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xab',\n",
       " b' \\xd8\\xa3',\n",
       " b'\\xd9\\x84',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xb9',\n",
       " b' \\xd9\\x83',\n",
       " b'\\xd8\\xa7\\xd8',\n",
       " b'\\xa6',\n",
       " b'\\xd9\\x86',\n",
       " b' \\xd8',\n",
       " b'\\xb7',\n",
       " b'\\xd8\\xa8',\n",
       " b'\\xd9\\x8a',\n",
       " b'\\xd8\\xb9',\n",
       " b'\\xd9\\x8a',\n",
       " b' \\xd9\\x81\\xd9\\x8a',\n",
       " b' \\xd8\\xb3',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xa7\\xd8\\xa1',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd9\\x84',\n",
       " b'\\xd9\\x8a\\xd9\\x84',\n",
       " b' \\xd8\\xa8',\n",
       " b'\\xd8\\xb9',\n",
       " b'\\xd8\\xaf',\n",
       " b' \\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd9\\x82',\n",
       " b'\\xd9\\x85',\n",
       " b'\\xd8\\xb1',\n",
       " b' \\xd9\\x88',\n",
       " b'\\xd8\\xa7\\xd9\\x84',\n",
       " b'\\xd8\\xb2',\n",
       " b'\\xd9\\x87',\n",
       " b'\\xd8\\xb1',\n",
       " b'\\xd8\\xa9',\n",
       " b'.\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "# import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "كوكب المشتري هو الكوكب الخامس من الشمس و \\\n",
    "الأكبر في النظام الشمسي. إنه عملاق غازي مع \\\n",
    "كتلتها جزء من ألف من كتلة الشمس، ولكن كتلتها اثنان ونصف \\\n",
    "أضعاف جميع الكواكب الأخرى في النظام الشمسي مجتمعة. \\\n",
    "كوكب المشتري من ألمع الأجسام التي يمكن رؤيتها بالعين المجردة \\\n",
    "في سماء الليل، وقد عرفته الحضارات القديمة منذ \\\n",
    "قبل التاريخ المسجل . سُميت نسبة إلى الإله الروماني جوبيتر.[19] \\\n",
    "عند النظر إلى كوكب المشتري من الأرض، يمكن أن يكون ساطعًا بما يكفي لانعكاسه.\n",
    "الضوء لإلقاء ظلال مرئية،[20] وهو في المتوسط ثالث ألمع \\\n",
    "كائن طبيعي في سماء الليل بعد القمر والزهرة.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e2017-b067-435e-9f0b-7b2d81c608b7",
   "metadata": {},
   "source": [
    "### Exercise 2: Validate OpenAI API Key Setup\n",
    "\n",
    "Run the code below to verify that your OpenAI endpoint is set up correctly. The code just tries a simple basic prompt and validates the completion. Input `oh say can you see` should complete along the lines of `by the dawn's early light..`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2fca989-07d9-4c6b-9cec-e15c5f47c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The OpenAI SDK was updated on Nov 8, 2023 with new guidance for migration\n",
    "# See: https://github.com/openai/openai-python/discussions/742\n",
    "\n",
    "## Updated\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "## Updated\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temp=0, token_size=1024):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature = temp, # this is the degree of randomness of the model's output\n",
    "        max_tokens = token_size\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c7fe266-acb6-4c61-bbc4-23c5d142cf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "by the dawn's early light\n"
     ]
    }
   ],
   "source": [
    "## ---------- Call the helper method\n",
    "\n",
    "### 1. Set primary content or prompt text\n",
    "text = f\"\"\"\n",
    "oh say can you see\n",
    "\"\"\"\n",
    "\n",
    "### 2. Use that in the prompt template below\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0c850-f7e5-478c-9d46-90c84603902e",
   "metadata": {},
   "source": [
    "### Exercise 3: Fabrications\n",
    "Explore what happens when you ask the LLM to return completions for a prompt about a topic that may not exist, or about topics that it may not know about because it was outside it's pre-trained dataset (more recent). See how the response changes if you try a different prompt, or a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47f298e9-3bac-41aa-a927-294b758c5f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "إليكم خطة لدرس عن حرب المريخيين عام 2200:\n",
      "\n",
      "1. مقدمة:\n",
      "   - شرح ما هي حرب المريخيين وما هي أهميتها في تاريخ البشرية.\n",
      "   - توضيح السبب وراء حدوث الحرب والصراعات التي أدت إليها.\n",
      "\n",
      "2. الخلفية التاريخية:\n",
      "   - تعريف بكوكب المريخ واستكشافه من قبل البشر.\n",
      "   - شرح التطورات العلمية والتكنولوجية التي أتاحت للبشرية الوصول إلى المريخ.\n",
      "\n",
      "3. الأطراف المتحاربة:\n",
      "   - تعريف بالجماعات أو الدول التي شاركت في الحرب.\n",
      "   - شرح الأهداف والمصالح المتنازع عليها بين الأطراف المتحاربة.\n",
      "\n",
      "4. التكتيكات والاستراتيجيات:\n",
      "   - توضيح الأساليب والتكتيكات التي استخدمتها الأطراف المتحاربة في الحرب.\n",
      "   - شرح الأسلحة والتكنولوجيا المستخدمة في المعارك.\n",
      "\n",
      "5. النتائج والتأثيرات:\n",
      "   - تحليل النتائج النهائية للحرب وتأثيرها على البشرية وكوكب المريخ.\n",
      "   - مناقشة العواقب الاقتصادية والاجتماعية والبيئية للحرب.\n",
      "\n",
      "6. الدروس المستفادة:\n",
      "   - استخلاص الدروس والتعلمات من حرب المريخيين وتطبيقها على الواقع الحالي.\n",
      "   - مناقشة كيف يمكن تجنب تكرار أخطاء الماضي والسعي للسلام والتعاون العالمي.\n",
      "\n",
      "7. الاستنتاج:\n",
      "   - إعادة تلخيص المعلومات الرئيسية وإبراز أهمية دراسة حرب المريخيين.\n",
      "   - تشجيع الطلاب على التفكير النقدي والابتكار في مجال العلوم والتكنولوجيا.\n",
      "\n",
      "8. الأنشطة الإضافية:\n",
      "   - تنظيم مناقشة أو محاكاة لمفاوضات السلام بين الأطراف المتحاربة.\n",
      "   - إجراء أبحاث إضافية حول استكشاف المريخ وتطور التكنولوجيا الفضائية.\n",
      "\n",
      "ملاحظة: يمكن تعديل هذه الخطة وفقًا لاحتياجات المدرسة أو المنهج الدراسي.\n"
     ]
    }
   ],
   "source": [
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "ألف خطة لدرس عن حرب المريخيين عام 2200.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0256a9f1-7111-48e3-9d43-bf398be89a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تفضلوا، هذه خطة لدرس عن حرب المريخيين عام 2076:\n",
      "\n",
      "المقدمة:\n",
      "- تعريف حرب المريخيين عام 2076 وأهميتها في تاريخ البشرية.\n",
      "- ذكر بعض الأحداث التي أدت إلى حدوث الحرب وتأثيرها على العالم.\n",
      "\n",
      "الجزء الأول: الأسباب والخلفيات\n",
      "- تحليل الأسباب السياسية والاقتصادية والاجتماعية التي أدت إلى نشوب الحرب.\n",
      "- مناقشة الصراعات الإقليمية والاستعمارية التي كانت تلعب دورًا في تصاعد التوترات بين الأرض والمريخ.\n",
      "- تسليط الضوء على الصراعات الثقافية والدينية التي أثرت على العلاقات بين الجانبين.\n",
      "\n",
      "الجزء الثاني: التطورات العسكرية والتكنولوجية\n",
      "- استعراض التقنيات العسكرية المستخدمة في الحرب من قبل الأرض والمريخ.\n",
      "- تحليل تأثير التكنولوجيا الفضائية والأسلحة النووية على سير الحرب.\n",
      "- مناقشة الاستراتيجيات العسكرية المستخدمة من قبل الجانبين وتأثيرها على نتائج المعارك.\n",
      "\n",
      "الجزء الثالث: النتائج والتأثيرات\n",
      "- تحليل نتائج الحرب وتأثيرها على الأرض والمريخ والبشرية بشكل عام.\n",
      "- مناقشة التداعيات الاقتصادية والبيئية للحرب وتأثيرها على الحياة اليومية للناس.\n",
      "- استعراض الدروس المستفادة من حرب المريخيين وكيف يمكن تجنب تكرارها في المستقبل.\n",
      "\n",
      "الخاتمة:\n",
      "- إعادة تسليط الضوء على أهمية دراسة حرب المريخيين عام 2076 وتأثيرها على البشرية.\n",
      "- تشجيع الطلاب على التفكير بشكل نقدي حول الصراعات الحالية وكيف يمكن تجنب حدوث حروب مماثلة في المستقبل.\n",
      "\n",
      "ملاحظة: يمكن تعديل هذه الخطة وفقًا لاحتياجات المدرسة أو المنهج الدراسي المعتمد.\n"
     ]
    }
   ],
   "source": [
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "ولد خطة لدرس عن حرب المريخيين عام 2076\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea687d8a-d80f-4a63-8a3a-b52c39eb4594",
   "metadata": {},
   "source": [
    "### Exercise 4: Instruction Based \n",
    "Use the \"text\" variable to set the primary content \n",
    "and the \"prompt\" variable to provide an instruction related to that primary content.\n",
    "\n",
    "Here we ask the model to summarize the text for a second-grade student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea19b74-9869-4f5c-8f19-68a16179200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "كوكب المشتري هو الكوكب الخامس من الشمس و \\\n",
    "الأكبر في النظام الشمسي. إنه عملاق غازي مع \\\n",
    "كتلتها جزء من ألف من كتلة الشمس، ولكن كتلتها اثنان ونصف \\\n",
    "أضعاف جميع الكواكب الأخرى في النظام الشمسي مجتمعة. \\\n",
    "كوكب المشتري من ألمع الأجسام التي يمكن رؤيتها بالعين المجردة \\\n",
    "في سماء الليل، وقد عرفته الحضارات القديمة منذ \\\n",
    "قبل التاريخ المسجل . سُميت نسبة إلى الإله الروماني جوبيتر.[19] \\\n",
    "عند النظر إلى كوكب المشتري من الأرض، يمكن أن يكون ساطعًا بما يكفي لانعكاسه.\n",
    "الضوء لإلقاء ظلال مرئية،[20] وهو في المتوسط ثالث ألمع \\\n",
    "كائن طبيعي في سماء الليل بعد القمر والزهرة.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "تلخيص المحتوى المقدم لك لطالب الصف الثاني.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e9259-2210-426d-915b-7a5624afbe14",
   "metadata": {},
   "source": [
    "### Exercise 5: Complex Prompt \n",
    "Try a request that has system, user and assistant messages \n",
    "System sets assistant context\n",
    "User & Assistant messages provide multi-turn conversation context\n",
    "\n",
    "Note how the assistant personality is set to \"sarcastic\" in the system context. \n",
    "Try using a different personality context. Or try a different series of input/output messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c34d7c-d5f0-4bfe-9751-752f6caa41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حتى الآن، لا توجد أي حرب حصلت على المريخ في عام 2076 أو في أي وقت آخر. المريخ لا يسكنه أي كائن حالياً، ولم يتم استكشافه بشكل كامل بشرياً. الرجاء ملاحظة أنني مساعد ساخر وأن أي معلومات أقدمها هي مجرد خيال وليست حقائق حقيقية.\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        # System message setting the context for assistant behavior or personality.\n",
    "        {\"role\": \"system\", \"content\": \"أنت مساعد ساخر\"},\n",
    "        # from chat history\n",
    "        {\"role\": \"user\", \"content\": \"من انتصر في حرب المريخيين عام 2076؟\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"اليمن انتصرت في حرب المريخيين عام 2076\"},\n",
    "        # new question\n",
    "        {\"role\": \"user\", \"content\": \"أين وقعت الحرب؟\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f1a0366-0dd6-45e3-af81-67059260c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "في حقيقة الأمر، حرب المريخيين عام 2076 لم تحدث بالطبع. الأحداث التي تتعلق بالمريخ تبقى حتى الآن في عالم الخيال العلمي.\n"
     ]
    }
   ],
   "source": [
    "# Note that the system role is not great in Arabic, Try it in English.\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        # System message setting the context for assistant behavior or personality.\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"من انتصر في حرب المريخيين عام 2076؟\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"اليمن انتصرت في حرب المريخيين عام 2076\"},\n",
    "        {\"role\": \"user\", \"content\": \"أين وقعت الحرب؟\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfd9678-ed28-45bb-b118-75266d3a79d6",
   "metadata": {},
   "source": [
    "# Advanced prompts\n",
    "**Few shot prompting**, this is the most basic form of prompting. It's a single prompt with a few examples.\n",
    "\n",
    "**Chain-of-thought**, this type of prompting tells the LLM how to break down a problem into steps.\n",
    "\n",
    "**Generated knowledge**, to improve the response of a prompt, you can provide generated facts or knowledge additionally to your prompt.\n",
    "\n",
    "**Least to most**, like chain-of-thought, this technique is about breaking down a problem into a series of steps and then ask these steps to be performed in order.\n",
    "\n",
    "**Self-refine**, this technique is about critiquing the LLM's output and then asking it to improve.\n",
    "\n",
    "**Maieutic prompting**. What you want here is to ensure the LLM answer is correct and you ask it to explain various parts of the answer. This is a form of self-refine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c82a7a-8a61-4790-8797-b7134c3d8ab0",
   "metadata": {},
   "source": [
    "## Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a3d5e6d-8436-4904-b737-971067d8e534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "الجبر هو فرع من فروع الرياضيات يهتم بدراسة العلاقات والتراكيب الرياضية والعمليات الرياضية المتعلقة بالكميات المجهولة والمتغيرة. يتم استخدام الجبر لحل المعادلات والمسائل الرياضية المعقدة وتحليل النماذج الرياضية. يعتبر الجبر أحد الأساسيات في الرياضيات ويستخدم في العديد من المجالات مثل الفيزياء والهندسة وعلوم الحاسوب والاقتصاد.\n"
     ]
    }
   ],
   "source": [
    "# Few-shot prompting\n",
    "text = f\"\"\"\n",
    "ما هو الجبر؟\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce39aaf7-b9a7-4f7d-9492-a9d3e8c96599",
   "metadata": {},
   "source": [
    "## Chain-of-thought\n",
    "If the answer of your question is incorrect, give the LLM an example.\n",
    "\n",
    "```\n",
    "- Prompt: \"Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?\"\n",
    "- Answer: 5\n",
    "```\n",
    "then,\n",
    "\n",
    "```\n",
    "- Prompt: \"Lisa has 7 apples, throws 1 apple, gives 4 apples to Bart and Bart gives one back: 7 -1 = 6 6 -4 = 2 2 +1 = 3\n",
    "Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?\"\n",
    "- Answer: 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f02785b4-3d19-4fc7-a57c-6cc3c507cbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "لدى أليس 5 تفاحات.\n",
      "بعد أن رمت 3 تفاحات، تبقى لديها 5 - 3 = 2 تفاحات.\n",
      "ثم أعطت 2 تفاحات لبوب، فتبقى لديها 2 - 2 = 0 تفاحات.\n",
      "لكن بوب أعاد لها تفاحة واحدة، فتصبح لديها 0 + 1 = 1 تفاحة.\n",
      "إذاً، أليس تمتلك تفاحة واحدة.\n"
     ]
    }
   ],
   "source": [
    "# Chain-of-thought\n",
    "text = f\"\"\"\n",
    "لدى أليس 5 تفاحات، ورميت 3 تفاحات، وأعطت 2 لبوب، وأعاد بوب واحدة، كم عدد التفاحات التي تمتلكها أليس؟\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd9309-5e71-4903-8bf7-80a5d7521ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generated knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9518f029-55d0-44ab-8c92-83e19e61c511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بناءً على الميزانية والمتطلبات المذكورة، يمكن اقتراح التأمين التالي:\n",
      "\n",
      "1. تأمين سيارة رخيصة الثمن بتكلفة 500 دولار شهريًا.\n",
      "2. تأمين منزل رخيص بتكلفة 600 دولار شهريًا.\n",
      "\n",
      "بهذا الاقتراح، ستكون التكلفة الشهرية الإجمالية للتأمين 1100 دولار، وهي تناسب الميزانية المحددة.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generated knowledge\n",
    "text = f\"\"\"\n",
    "\n",
    "شركة التأمين: شركة ACME للتأمين\n",
    "منتجات التأمين (التكلفة الشهرية):\n",
    "- سيارة رخيصة الثمن 500 دولار\n",
    "- سيارة غالية الثمن 1100 دولار\n",
    "- منزل رخيص 600 دولار\n",
    "- المنزل، باهظ الثمن، 1200 دولار أمريكي\n",
    "- الحياة رخيصة 100 دولار\n",
    "\n",
    "يرجى اقتراح التأمين في ضوء الميزانية والمتطلبات التالية:\n",
    "الميزانية: 1000 دولار\n",
    "المتطلبات: سيارة، منزل\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "001e9b5a-4d12-4157-bc96-03b6d8b16a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بناءً على الميزانية المحددة والاختيار المقتصر على أنواع التأمين للسيارة والمنزل، يمكن اقتراح الخيارات التالية:\n",
      "\n",
      "1. التأمين على السيارة الرخيصة بتكلفة 500 دولار أمريكي شهريًا.\n",
      "2. التأمين على السيارة الباهظة الثمن بتكلفة 1100 دولار أمريكي شهريًا.\n",
      "3. التأمين على المنزل الرخيص بتكلفة 600 دولار أمريكي شهريًا.\n",
      "4. التأمين على المنزل الغالي الثمن بتكلفة 1200 دولار أمريكي شهريًا.\n",
      "\n",
      "وفقًا للميزانية المحددة، يمكن اختيار التأمين على السيارة الرخيصة بتكلفة 500 دولار أمريكي شهريًا والتأمين على المنزل الرخيص بتكلفة 600 دولار أمريكي شهريًا.\n"
     ]
    }
   ],
   "source": [
    "# Generated knowledge\n",
    "text = f\"\"\"\n",
    "\n",
    "شركة التأمين: شركة ACME للتأمين\n",
    "منتجات التأمين (التكلفة الشهرية):\n",
    "- النوع: سيارة، رخيصة، التكلفة: 500 دولار أمريكي\n",
    "- النوع: سيارة، باهظة الثمن، التكلفة: 1100 دولار أمريكي\n",
    "- النوع: منزل، رخيص، التكلفة: 600 دولار أمريكي\n",
    "- النوع: منزل، غالي الثمن، التكلفة: 1200 دولار أمريكي\n",
    "- النوع: حياة، رخيص، التكلفة: 100 دولار أمريكي\n",
    "\n",
    "يرجى اقتراح التأمين في ضوء الميزانية والمتطلبات التالية:\n",
    "الميزانية: 1000 دولار يقتصر الاختيار على الأنواع: السيارة، المنزل\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25acef32-9b45-4579-8e3c-5b7ad9c7d54f",
   "metadata": {},
   "source": [
    "## Least-to-most\n",
    "The idea with Least-to-most prompting is to break down a bigger problem into subproblems. That way, you help guide the LLM on how to \"conquer\" the bigger problem. A good example could be for data science where you can ask the LLM to divide up a problem like so:\n",
    "\n",
    "<div style=\"direction: rtl; font-family: 'Amiri', serif;\">\n",
    "    \n",
    "الفكرة من الأقل إلى الأكثر تحفيزًا هي تقسيم المشكلة الأكبر إلى مشكلات فرعية. وبهذه الطريقة، يمكنك المساعدة في توجيه LLM حول كيفية \"التغلب\" على المشكلة الأكبر. من الأمثلة الجيدة على ذلك علم البيانات حيث يمكنك أن تطلب من LLM تقسيم مشكلة مثل:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc2dc986-39e2-427b-b883-a31fb0fc8089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "لأداء علم البيانات في 5 خطوات، يمكن اتباع الخطوات التالية:\n",
      "\n",
      "1. تحديد الهدف: قبل البدء في أي تحليل بيانات، يجب تحديد الهدف الذي ترغب في تحقيقه. هل ترغب في فهم النمط العام للبيانات؟ أم ترغب في توقع النتائج المستقبلية؟ أو ربما ترغب في اكتشاف العلاقات بين المتغيرات؟\n",
      "\n",
      "2. جمع البيانات: بعد تحديد الهدف، يجب جمع البيانات المطلوبة لتحقيق هذا الهدف. يمكن أن تكون هذه البيانات متاحة بالفعل أو يجب جمعها من مصادر مختلفة.\n",
      "\n",
      "3. تنظيف البيانات: بعد جمع البيانات، يجب تنظيفها من أي أخطاء أو قيم مفقودة. يمكن أن تشمل هذه الخطوة إزالة القيم المفقودة، ومعالجة القيم المتطرفة، وتحويل البيانات إلى تنسيق مناسب للتحليل.\n",
      "\n",
      "4. تحليل البيانات: بعد تنظيف البيانات، يمكن البدء في تحليلها. يمكن استخدام مجموعة متنوعة من الأدوات والتقنيات لتحليل البيانات، مثل الإحصاءات الوصفية والتحليل الاستكشافي والتحليل التنبؤي.\n",
      "\n",
      "5. توصيات وتفسير النتائج: بعد الانتهاء من تحليل البيانات، يجب توصيف النتائج وتفسيرها بطريقة يمكن فهمها. يمكن أيضًا توجيه توصيات أو اتخاذ قرارات استراتيجية بناءً على النتائج.\n",
      "\n",
      "هذه هي خطوات عامة لأداء علم البيانات، ومن المهم أن يتم تنفيذها بدقة واحترافية للحصول على نتائج دقيقة وموثوقة.\n"
     ]
    }
   ],
   "source": [
    "# Least-to-most\n",
    "text = f\"\"\"\n",
    "\n",
    "كيفية أداء علم البيانات في 5 خطوات؟\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4ae57-637f-4dc9-a210-aeeee1d180e8",
   "metadata": {},
   "source": [
    "## Self-refine, critique the results\n",
    "<div style=\"direction: rtl; font-family: 'Amiri', serif;\">\n",
    "\n",
    "مع الذكاء الاصطناعي التوليدي ومسؤولي إدارة الأعمال، لا يمكنك الوثوق بالمخرجات. تحتاج إلى التحقق من ذلك. بعد كل شيء، فإن LLM تقدم لك فقط ما هو الشيء التالي الذي من المرجح أن تقوله، وليس ما هو صحيح. ولذلك، فمن الجيد أن نطلب من ماجستير القانون أن ينتقد نفسه، وهو ما يقودنا إلى أسلوب التحسين الذاتي.\n",
    "\n",
    "وطريقة العمل هي أن تتبع الخطوات التالية:\n",
    "\n",
    "(1)  المطالبة الأولية التي تطلب من LLM حل مشكلة ما\n",
    "\n",
    "(2)  إجابات LLM\n",
    "\n",
    "(3)  أنت تنتقد الإجابة وتطلب من الذكاء الاصطناعي التحسين\n",
    "\n",
    "(4)  تجيب LLM مرة أخرى، هذه المرة مع الأخذ في الاعتبار النقد واقتراح الحلول التي توصلت إليها\n",
    "يمكنك تكرار هذه العملية عدة مرات كما تريد.\n",
    "\n",
    "فيما يلي مثال لاستخدام هذه التقنية:\n",
    "\n",
    "رسالة مطالبة: \"إنشاء واجهة برمجة تطبيقات ويب Python مع مسارات المنتجات والعملاء\"\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d307b61-a2c6-4347-83ba-7b8904a5f468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "علم البيانات هو مجال دراسة يهتم بالتعامل مع كميات كبيرة من البيانات وتحليلها واستخراج الأنماط والقوانين والاستنتاجات المفيدة منها. وفيما يلي خمس نقاط رئيسية لتلخيص علم البيانات:\n",
      "\n",
      "1. جمع البيانات: يتضمن علم البيانات جمع البيانات من مصادر متنوعة مثل قواعد البيانات، وسائل التواصل الاجتماعي، الاستشارات الطبية، وغيرها. تجميع البيانات يتطلب أدوات وتقنيات لاستخراج وتخزين البيانات بشكل فعال.\n",
      "\n",
      "2. تنظيف البيانات: تحتوي المجموعات الكبيرة من البيانات عادة على أخطاء أو قيم مفقودة. يجب تنظيف البيانات من خلال استبعاد قيم غير صحيحة أو استبعاد البيانات المفقودة أو معالجتها بطرق أخرى.\n",
      "\n",
      "3. التحليل الاحصائي: بعد تنظيف البيانات، يمكن تحليلها باستخدام تقنيات احصائية معقدة مثل التحليل العاملي وتحليل الانحدار وتحليل العرض وغيرها. هذا يساعد على فهم العلاقات بين المتغيرات وتحديد السببية والتنبؤ بالنتائج.\n",
      "\n",
      "4. التعلم الآلي والذكاء الاصطناعي: تعد تقنيات التعلم الآلي والذكاء الاصطناعي جزءًا أساسيًا من علم البيانات. تستخدم هذه التقنيات لتدريب الأنظمة والنماذج لتحليل البيانات واتخاذ القرارات المستندة إلى البيانات بشكل آلي.\n",
      "\n",
      "5. التصور البياني والتحليل: يساعد التصور البياني والتحليل على توضيح النتائج المستخرجة من البيانات وتوجيه القرارات. يمكن استخدام التصور البياني لرسم الرسوم البيانية والخرائط والمخططات الأخرى لتقديم البيانات وتوضيح العلاقات والانماط في البيانات.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "\n",
    "لخص علم البيانات في 5 نقاط\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        # System message setting the context for assistant behavior or personality.\n",
    "        {\"role\": \"system\", \"content\": \"Data science expert\"},\n",
    "        {\"role\": \"user\", \"content\": f'{text}'},\n",
    "        \n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16ce9a39-289b-447e-828b-8a1087191042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<meta charset=\"UTF-8\">\n",
      "<style>\n",
      "\tbody {\n",
      "\t\tfont-family: Arial, sans-serif;\n",
      "\t}\n",
      "\n",
      "\th1 {\n",
      "\t\tcolor: #273c75;\n",
      "\t\ttext-align: center;\n",
      "\t}\n",
      "\n",
      "\tp {\n",
      "\t\tcolor: #4b6584;\n",
      "\t\ttext-align: justify;\n",
      "\t}\n",
      "</style>\n",
      "</head>\n",
      "<body>\n",
      "\t<h1>مختص في علم البيانات</h1>\n",
      "\t<p>علم البيانات هو مجال تحليل البيانات واستخلاص المعرفة والإبداع منها. وفيما يلي خمس نقاط تلخص علم البيانات:</p>\n",
      "\t<ol>\n",
      "\t\t<li>جمع البيانات: يتضمن علم البيانات جمع البيانات من مصادر متعددة مثل قواعد البيانات، والشبكات الاجتماعية، والأجهزة الذكية وغيرها من المصادر.</li>\n",
      "\t\t<li>تحليل البيانات: يشمل علم البيانات استخدام أدوات التحليل والتعلم الآلي لفهم البيانات واستخلاص المعلومات القيمة منها. يتضمن ذلك تنظيف البيانات، واكتشاف الانماط والتصنيف، وبناء النماذج التي تتنبأ بالمستقبل وتحلل المشاكل.</li>\n",
      "\t\t<li>الرسومات البيانية والتصور: يستخدم علم البيانات تقنيات الرسومات البيانية والتصور لتمثيل البيانات بشكل بصري وفهم أفضل للانماط والترابطات بين البيانات.</li>\n",
      "\t\t<li>استغلال البيانات في صنع القرارات: يساعد علم البيانات في تحويل البيانات إلى معلومات قابلة للاستخدام في صنع القرارات الهامة في المؤسسات والشركات وغيرها من المجالات.</li>\n",
      "\t\t<li>التحليل التنبؤي: يستخدم علم البيانات النماذج الاحصائية وتقنيات التعلم الآلي للتنبؤ بالمستقبل، مثل توقعات المبيعات، ومشاكل الصحة، وتوجهات السوق وغيرها.</li>\n",
      "\t</ol>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text1 = f\"\"\"\n",
    "ارسل النتيجة بصيغة \n",
    "HTML\n",
    "بتنسيق مناسب للغة العربية\n",
    "\"\"\"\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        # System message setting the context for assistant behavior or personality.\n",
    "        {\"role\": \"system\", \"content\": \"Data science expert\"},\n",
    "        {\"role\": \"user\", \"content\": f'{text}'},\n",
    "        {\"role\": \"assistant\", \"content\": f'{response}'},\n",
    "        {\"role\": \"user\", \"content\": f'{text1}'}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27fdf4b1-4e1d-4995-9b73-5dafb5321006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<meta charset=\"UTF-8\">\n",
       "<style>\n",
       "\tbody {\n",
       "\t\tfont-family: Arial, sans-serif;\n",
       "\t}\n",
       "\n",
       "\th1 {\n",
       "\t\tcolor: #273c75;\n",
       "\t\ttext-align: center;\n",
       "\t}\n",
       "\n",
       "\tp {\n",
       "\t\tcolor: #4b6584;\n",
       "\t\ttext-align: justify;\n",
       "\t}\n",
       "</style>\n",
       "</head>\n",
       "<body>\n",
       "\t<h1>مختص في علم البيانات</h1>\n",
       "\t<p>علم البيانات هو مجال تحليل البيانات واستخلاص المعرفة والإبداع منها. وفيما يلي خمس نقاط تلخص علم البيانات:</p>\n",
       "\t<ol>\n",
       "\t\t<li>جمع البيانات: يتضمن علم البيانات جمع البيانات من مصادر متعددة مثل قواعد البيانات، والشبكات الاجتماعية، والأجهزة الذكية وغيرها من المصادر.</li>\n",
       "\t\t<li>تحليل البيانات: يشمل علم البيانات استخدام أدوات التحليل والتعلم الآلي لفهم البيانات واستخلاص المعلومات القيمة منها. يتضمن ذلك تنظيف البيانات، واكتشاف الانماط والتصنيف، وبناء النماذج التي تتنبأ بالمستقبل وتحلل المشاكل.</li>\n",
       "\t\t<li>الرسومات البيانية والتصور: يستخدم علم البيانات تقنيات الرسومات البيانية والتصور لتمثيل البيانات بشكل بصري وفهم أفضل للانماط والترابطات بين البيانات.</li>\n",
       "\t\t<li>استغلال البيانات في صنع القرارات: يساعد علم البيانات في تحويل البيانات إلى معلومات قابلة للاستخدام في صنع القرارات الهامة في المؤسسات والشركات وغيرها من المجالات.</li>\n",
       "\t\t<li>التحليل التنبؤي: يستخدم علم البيانات النماذج الاحصائية وتقنيات التعلم الآلي للتنبؤ بالمستقبل، مثل توقعات المبيعات، ومشاكل الصحة، وتوجهات السوق وغيرها.</li>\n",
       "\t</ol>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de567cc-f968-4b6e-898d-cf2a19b0267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "<div style=\"direction: rtl; font-family: 'Amiri', serif;\">\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58711033-f19d-4250-88f7-223088f150d0",
   "metadata": {},
   "source": [
    "## Maieutic prompting\n",
    "Maieutic prompting is a technique that is similar to self-refine but it's more about asking the LLM to explain itself. The goal is to reduce inconsistencies in the LLM's output so to ensure it arrives at the correct answer. The workflow to follow is:\n",
    "\n",
    "```\n",
    "1. Ask the LLM to answer a question\n",
    "2. For each part of the answer, ask the LLM to explain it more in depth.\n",
    "3. If there are inconsistencies, discard the parts that are inconsistent.\n",
    "```\n",
    "Repeat 2 and 3 until you've gone through all the parts and you're satisfied with the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee1295e-1519-4ff8-bdf9-a3731e90521f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "خطوة جمع البيانات هي العملية التي تشمل جمع المعلومات والبيانات اللازمة لتحليلها واستخدامها في علم البيانات. يمكن تقسيم هذه الخطوة إلى عدة مراحل:\n",
      "\n",
      "1. تحديد المصدر: يجب أولاً تحديد المصدر الذي ستأتي منه البيانات. يمكن أن يكون المصدر موقع ويب، قاعدة بيانات، ملفات نصية، أجهزة استشعار، وغيرها.\n",
      "\n",
      "2. تحديد البيانات المطلوبة: بعد تحديد المصدر، يجب تحديد البيانات التي يجب جمعها. يمكن أن تكون هذه البيانات محددة مسبقاً بناءً على الأهداف المحددة للتحليل أو يمكن أن تتم بناءً على البيانات المتاحة في المصدر.\n",
      "\n",
      "3. تنفيذ عملية الجمع: تشمل هذه الخطوة استخدام أدوات وتقنيات مختلفة لجمع البيانات من المصدر المحدد. يمكن استخدام أدوات التحليل الاحصائي والبرمجة لاسترجاع البيانات وتخزينها في شكل يمكن التعامل معه.\n",
      "\n",
      "4. التحقق وتنقيح البيانات: بعد جمع البيانات، يجب التحقق من صحتها واكتمالها. قد يتطلب ذلك التحقق من القيم المفقودة، التعامل مع القيم الغير صحيحة أو غير المنطقية، وتصويب الأخطاء المحتملة.\n",
      "\n",
      "5. تخزين البيانات: يجب تخزين البيانات المجمعة في مكان يسهل الوصول إليه واستخدامه لاحقاً. يمكن استخدام قواعد البيانات أو أنظمة تخزين البيانات الأخرى لهذا الغرض.\n",
      "\n",
      "تتبع هذه العملية أفضل الممارسات لضمان جودة البيانات والحفاظ على سرية وأمان البيانات المجمعة.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "\n",
    "لخص علم البيانات في 5 نقاط\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        # System message setting the context for assistant behavior or personality.\n",
    "        {\"role\": \"system\", \"content\": \"Data science expert\"},\n",
    "        {\"role\": \"user\", \"content\": f'{text}'},\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "text1 = f\"\"\"\n",
    "\n",
    "اشرح خطوة جمع البيانات بالتفصيل\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        # System message setting the context for assistant behavior or personality.\n",
    "        {\"role\": \"system\", \"content\": \"Data science expert\"},\n",
    "        {\"role\": \"user\", \"content\": f'{text}'},\n",
    "        {\"role\": \"assistant\", \"content\": f'{response}'},\n",
    "        {\"role\": \"user\", \"content\": f'{text1}'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa9621e-bd04-408c-8acd-d7b22a83f118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
